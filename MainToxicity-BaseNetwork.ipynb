{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xd4z51bEpNzh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def denormalize(T, coords):\n",
    "    return (0.5 * ((coords + 1.0) * T))\n",
    "\n",
    "\n",
    "def bounding_box(x, y, size, color='w'):\n",
    "    x = int(x - (size / 2))\n",
    "    y = int(y - (size / 2))\n",
    "    rect = patches.Rectangle(\n",
    "        (x, y), size, size, linewidth=1, edgecolor=color, fill=False\n",
    "    )\n",
    "    return rect\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and\n",
    "    current value.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def resize_array(x, size):\n",
    "    # 3D and 4D tensors allowed only\n",
    "    assert x.ndim in [3, 4], \"Only 3D and 4D Tensors allowed!\"\n",
    "\n",
    "    # 4D Tensor\n",
    "    if x.ndim == 4:\n",
    "        res = []\n",
    "        for i in range(x.shape[0]):\n",
    "            img = array2img(x[i])\n",
    "            img = img.resize((size, size))\n",
    "            img = np.asarray(img, dtype='float32')\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            img /= 255.0\n",
    "            res.append(img)\n",
    "        res = np.concatenate(res)\n",
    "        res = np.expand_dims(res, axis=1)\n",
    "        return res\n",
    "\n",
    "    # 3D Tensor\n",
    "    img = array2img(x)\n",
    "    img = img.resize((size, size))\n",
    "    res = np.asarray(img, dtype='float32')\n",
    "    res = np.expand_dims(res, axis=0)\n",
    "    res /= 255.0\n",
    "    return res\n",
    "\n",
    "\n",
    "def img2array(data_path, desired_size=None, expand=False, view=False):\n",
    "    \"\"\"\n",
    "    Util function for loading RGB image into a numpy array.\n",
    "\n",
    "    Returns array of shape (1, H, W, C).\n",
    "    \"\"\"\n",
    "    img = Image.open(data_path)\n",
    "    img = img.convert('RGB')\n",
    "    if desired_size:\n",
    "        img = img.resize((desired_size[1], desired_size[0]))\n",
    "    if view:\n",
    "        img.show()\n",
    "    x = np.asarray(img, dtype='float32')\n",
    "    if expand:\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    x /= 255.0\n",
    "    return x\n",
    "\n",
    "\n",
    "def array2img(x):\n",
    "    \"\"\"\n",
    "    Util function for converting anumpy array to a PIL img.\n",
    "\n",
    "    Returns PIL RGB img.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    x = x + max(-np.min(x), 0)\n",
    "    x_max = np.max(x)\n",
    "    if x_max != 0:\n",
    "        x /= x_max\n",
    "    x *= 255\n",
    "    return Image.fromarray(x.astype('uint8'), 'RGB')\n",
    "\n",
    "\n",
    "def plot_images(images, gd_truth):\n",
    "\n",
    "    images = images.squeeze()\n",
    "    assert len(images) == len(gd_truth) == 9\n",
    "\n",
    "    # Create figure with sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # plot the image\n",
    "        ax.imshow(images[i], cmap=\"Greys_r\")\n",
    "\n",
    "        xlabel = \"{}\".format(gd_truth[i])\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def prepare_dirs(config):\n",
    "    for path in [config.data_dir, config.ckpt_dir, config.logs_dir]:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "\n",
    "def save_config(config):\n",
    "    model_name = 'ram_{}_{}x{}_{}'.format(\n",
    "        config.num_glimpses, config.patch_size,\n",
    "        config.patch_size, config.glimpse_scale\n",
    "    )\n",
    "    filename = model_name + '_params.json'\n",
    "    param_path = os.path.join(config.ckpt_dir, filename)\n",
    "\n",
    "    print(\"[*] Model Checkpoint Dir: {}\".format(config.ckpt_dir))\n",
    "    print(\"[*] Param Path: {}\".format(param_path))\n",
    "\n",
    "    with open(param_path, 'w') as fp:\n",
    "        json.dump(config.__dict__, fp, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "i0BpUNLlpNzl",
    "outputId": "31c3a99b-2349-490a-e48e-556b3d79d563",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(len(ds)):\\n    sample = ds[i]\\n    #print (type(sample['image']))\\n    print (i, sample['image'].shape, sample['y'])\\n    if i==3:\\n        break\\n\\ndata_loader = DataLoader(ds,batch_size = 4, shuffle = True)\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "#from utils import plot_images\n",
    "#from rdkit import Chem\n",
    "#from rdkit.Chem import Draw\n",
    "#from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "\n",
    "class ToxicDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        print (csv_file)\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.max_tox=self.data.loc[:, (self.data.columns != 'SMILES')& (self.data.columns !='Unnamed: 0')].as_matrix()\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.max_tox)\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,str(idx)+'.png')\n",
    "        image = io.imread(img_name)\n",
    "        image = image[np.newaxis, :, :]\n",
    "        image.astype(float)\n",
    "        y = self.max_tox[idx]\n",
    "        sample = {'image': image, 'y': y}\n",
    "        if self.transform:\n",
    "            sample = self.transform\n",
    "        return sample['image'], sample['y']\n",
    "    \n",
    "def get_train_valid_loader(data_dir,\n",
    "                           batch_size,\n",
    "                           random_seed,\n",
    "                           valid_size=0.1,\n",
    "                           shuffle=True,\n",
    "                           show_sample=False,\n",
    "                           num_workers=4,\n",
    "                           pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning train and valid\n",
    "    multi-process iterators over the MNIST dataset. A sample\n",
    "    9x9 grid of the images can be optionally displayed.\n",
    "\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - random_seed: fix seed for reproducibility.\n",
    "    - valid_size: percentage split of the training set used for\n",
    "      the validation set. Should be a float in the range [0, 1].\n",
    "      In the paper, this number is set to 0.1.\n",
    "    - shuffle: whether to shuffle the train/validation indices.\n",
    "    - show_sample: plot 9x9 sample grid of the dataset.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - train_loader: training set iterator.\n",
    "    - valid_loader: validation set iterator.\n",
    "    \"\"\"\n",
    "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
    "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
    "\n",
    "    # define transforms\n",
    "    #normalize = transforms.Normalize((0.1307,), (0.3081,))\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor()#, normalize,\n",
    "    ])\n",
    "\n",
    "    # load dataset\n",
    "\n",
    "    #dataset1 = datasets.MNIST(\n",
    "    #    data_dir, train=True, download=True, transform=trans\n",
    "    #)\n",
    "    dataset = ToxicDataset(csv_file=\"aggregate_tox.csv\", root_dir=\"../Data/\")\n",
    "\n",
    "    num_train = len(dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    # visualize some images\n",
    "    if show_sample:\n",
    "        sample_loader = torch.utils.data.DataLoader(\n",
    "            dataset, batch_size=9, shuffle=shuffle,\n",
    "            num_workers=num_workers, pin_memory=pin_memory\n",
    "        )\n",
    "        data_iter = iter(sample_loader)\n",
    "        images, labels = data_iter.next()\n",
    "        X = images.numpy()\n",
    "        X = np.transpose(X, [0, 2, 3, 1])\n",
    "        plot_images(X, labels)\n",
    "\n",
    "    return (train_loader, valid_loader)\n",
    "\n",
    "\n",
    "def get_test_loader(data_dir,\n",
    "                    batch_size,\n",
    "                    num_workers=4,\n",
    "                    pin_memory=False):\n",
    "    \"\"\"\n",
    "    Utility function for loading and returning a multi-process\n",
    "    test iterator over the MNIST dataset.\n",
    "\n",
    "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    - data_dir: path directory to the dataset.\n",
    "    - batch_size: how many samples per batch to load.\n",
    "    - num_workers: number of subprocesses to use when loading the dataset.\n",
    "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
    "      True if using GPU.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - data_loader: test set iterator.\n",
    "    \"\"\"\n",
    "    # define transforms\n",
    "    #normalize = transforms.Normalize((0.1307,), (0.3081,))\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor()#, normalize,\n",
    "    ])\n",
    "\n",
    "    # load dataset\n",
    "    dataset = ToxicDataset(csv_file=\"aggregate_tox.csv\", root_dir=\"../Data/\")\n",
    "    #dataset = datasets.MNIST(\n",
    "    #    data_dir, train=False, download=True, transform=trans\n",
    "    #)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "\n",
    "'''for i in range(len(ds)):\n",
    "    sample = ds[i]\n",
    "    #print (type(sample['image']))\n",
    "    print (i, sample['image'].shape, sample['y'])\n",
    "    if i==3:\n",
    "        break\n",
    "\n",
    "data_loader = DataLoader(ds,batch_size = 4, shuffle = True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Hh7QkY-pNzq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class retina(object):\n",
    "    \"\"\"\n",
    "    A retina that extracts a foveated glimpse `phi`\n",
    "    around location `l` from an image `x`. It encodes\n",
    "    the region around `l` at a high-resolution but uses\n",
    "    a progressively lower resolution for pixels further\n",
    "    from `l`, resulting in a compressed representation\n",
    "    of the original image `x`.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    - x: a 4D Tensor of shape (B, H, W, C). The minibatch\n",
    "      of images.\n",
    "    - l: a 2D Tensor of shape (B, 2). Contains normalized\n",
    "      coordinates in the range [-1, 1].\n",
    "    - g: size of the first square patch.\n",
    "    - k: number of patches to extract in the glimpse.\n",
    "    - s: scaling factor that controls the size of\n",
    "      successive patches.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - phi: a 5D tensor of shape (B, k, g, g, C). The\n",
    "      foveated glimpse of the image.\n",
    "    \"\"\"\n",
    "    def __init__(self, g, k, s):\n",
    "        self.g = g\n",
    "        self.k = k\n",
    "        self.s = s\n",
    "\n",
    "    def foveate(self, x, l):\n",
    "        \"\"\"\n",
    "        Extract `k` square patches of size `g`, centered\n",
    "        at location `l`. The initial patch is a square of\n",
    "        size `g`, and each subsequent patch is a square\n",
    "        whose side is `s` times the size of the previous\n",
    "        patch.\n",
    "\n",
    "        The `k` patches are finally resized to (g, g) and\n",
    "        concatenated into a tensor of shape (B, k, g, g, C).\n",
    "        \"\"\"\n",
    "        phi = []\n",
    "        size = self.g\n",
    "\n",
    "        # extract k patches of increasing size\n",
    "        for i in range(self.k):\n",
    "            phi.append(self.extract_patch(x, l, size))\n",
    "            size = int(self.s * size)\n",
    "\n",
    "        # resize the patches to squares of size g\n",
    "        for i in range(1, len(phi)):\n",
    "            k = phi[i].shape[-1] // self.g\n",
    "            phi[i] = F.avg_pool2d(phi[i], k)\n",
    "\n",
    "        # concatenate into a single tensor and flatten\n",
    "        phi = torch.cat(phi, 1)\n",
    "        phi = phi.view(phi.shape[0], -1)\n",
    "\n",
    "        return phi\n",
    "\n",
    "    def extract_patch(self, x, l, size):\n",
    "        \"\"\"\n",
    "        Extract a single patch for each image in the\n",
    "        minibatch `x`.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        - x: a 4D Tensor of shape (B, H, W, C). The minibatch\n",
    "          of images.\n",
    "        - l: a 2D Tensor of shape (B, 2).\n",
    "        - size: a scalar defining the size of the extracted patch.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - patch: a 4D Tensor of shape (B, size, size, C)\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # denormalize coords of patch center\n",
    "        coords = self.denormalize(H, l)\n",
    "\n",
    "        # compute top left corner of patch\n",
    "        patch_x = coords[:, 0] - (size // 2)\n",
    "        patch_y = coords[:, 1] - (size // 2)\n",
    "\n",
    "        # loop through mini-batch and extract\n",
    "        patch = []\n",
    "        for i in range(B):\n",
    "            im = x[i].unsqueeze(dim=0)\n",
    "            T = im.shape[-1]\n",
    "\n",
    "            # compute slice indices\n",
    "            from_x, to_x = patch_x[i], patch_x[i] + size\n",
    "            from_y, to_y = patch_y[i], patch_y[i] + size\n",
    "\n",
    "            # cast to ints\n",
    "            from_x, to_x = from_x.item(), to_x.item()\n",
    "            from_y, to_y = from_y.item(), to_y.item()\n",
    "\n",
    "            # pad tensor in case exceeds\n",
    "            if self.exceeds(from_x, to_x, from_y, to_y, T):\n",
    "                pad_dims = (\n",
    "                    size//2+1, size//2+1,\n",
    "                    size//2+1, size//2+1,\n",
    "                    0, 0,\n",
    "                    0, 0,\n",
    "                )\n",
    "                im = F.pad(im, pad_dims, \"constant\", 0)\n",
    "\n",
    "                # add correction factor\n",
    "                from_x += (size//2+1)\n",
    "                to_x += (size//2+1)\n",
    "                from_y += (size//2+1)\n",
    "                to_y += (size//2+1)\n",
    "\n",
    "            # and finally extract\n",
    "            patch.append(im[:, :, from_y:to_y, from_x:to_x])\n",
    "\n",
    "        # concatenate into a single tensor\n",
    "        patch = torch.cat(patch)\n",
    "\n",
    "        return patch\n",
    "\n",
    "    def denormalize(self, T, coords):\n",
    "        \"\"\"\n",
    "        Convert coordinates in the range [-1, 1] to\n",
    "        coordinates in the range [0, T] where `T` is\n",
    "        the size of the image.\n",
    "        \"\"\"\n",
    "        return (0.5 * ((coords + 1.0) * T)).long()\n",
    "\n",
    "    def exceeds(self, from_x, to_x, from_y, to_y, T):\n",
    "        \"\"\"\n",
    "        Check whether the extracted patch will exceed\n",
    "        the boundaries of the image of size `T`.\n",
    "        \"\"\"\n",
    "        if (\n",
    "            (from_x < 0) or (from_y < 0) or (to_x > T) or (to_y > T)\n",
    "        ):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class glimpse_network(nn.Module):\n",
    "    \"\"\"\n",
    "    A network that combines the \"what\" and the \"where\"\n",
    "    into a glimpse feature vector `g_t`.\n",
    "\n",
    "    - \"what\": glimpse extracted from the retina.\n",
    "    - \"where\": location tuple where glimpse was extracted.\n",
    "\n",
    "    Concretely, feeds the output of the retina `phi` to\n",
    "    a fc layer and the glimpse location vector `l_t_prev`\n",
    "    to a fc layer. Finally, these outputs are fed each\n",
    "    through a fc layer and their sum is rectified.\n",
    "\n",
    "    In other words:\n",
    "\n",
    "        `g_t = relu( fc( fc(l) ) + fc( fc(phi) ) )`\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    - h_g: hidden layer size of the fc layer for `phi`.\n",
    "    - h_l: hidden layer size of the fc layer for `l`.\n",
    "    - g: size of the square patches in the glimpses extracted\n",
    "      by the retina.\n",
    "    - k: number of patches to extract per glimpse.\n",
    "    - s: scaling factor that controls the size of successive patches.\n",
    "    - c: number of channels in each image.\n",
    "    - x: a 4D Tensor of shape (B, H, W, C). The minibatch\n",
    "      of images.\n",
    "    - l_t_prev: a 2D tensor of shape (B, 2). Contains the glimpse\n",
    "      coordinates [x, y] for the previous timestep `t-1`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - g_t: a 2D tensor of shape (B, hidden_size). The glimpse\n",
    "      representation returned by the glimpse network for the\n",
    "      current timestep `t`.\n",
    "    \"\"\"\n",
    "    def __init__(self, h_g, h_l, g, k, s, c):\n",
    "        super(glimpse_network, self).__init__()\n",
    "        self.retina = retina(g, k, s)\n",
    "\n",
    "        # glimpse layer\n",
    "        D_in = k*g*g*c\n",
    "        self.fc1 = nn.Linear(D_in, h_g)\n",
    "\n",
    "        # location layer\n",
    "        D_in = 2\n",
    "        self.fc2 = nn.Linear(D_in, h_l)\n",
    "\n",
    "        self.fc3 = nn.Linear(h_g, h_g+h_l)\n",
    "        self.fc4 = nn.Linear(h_l, h_g+h_l)\n",
    "\n",
    "    def forward(self, x, l_t_prev):\n",
    "        # generate glimpse phi from image x\n",
    "        phi = self.retina.foveate(x, l_t_prev)\n",
    "\n",
    "        # flatten location vector\n",
    "        l_t_prev = l_t_prev.view(l_t_prev.size(0), -1)\n",
    "\n",
    "        # feed phi and l to respective fc layers\n",
    "        #print(phi.type())\n",
    "        phi_out = F.relu(self.fc1(phi))\n",
    "        l_out = F.relu(self.fc2(l_t_prev))\n",
    "\n",
    "        what = self.fc3(phi_out)\n",
    "        where = self.fc4(l_out)\n",
    "\n",
    "        # feed to fc layer\n",
    "        g_t = F.relu(what + where)\n",
    "\n",
    "        return g_t\n",
    "\n",
    "\n",
    "class core_network(nn.Module):\n",
    "    \"\"\"\n",
    "    An RNN that maintains an internal state that integrates\n",
    "    information extracted from the history of past observations.\n",
    "    It encodes the agent's knowledge of the environment through\n",
    "    a state vector `h_t` that gets updated at every time step `t`.\n",
    "\n",
    "    Concretely, it takes the glimpse representation `g_t` as input,\n",
    "    and combines it with its internal state `h_t_prev` at the previous\n",
    "    time step, to produce the new internal state `h_t` at the current\n",
    "    time step.\n",
    "\n",
    "    In other words:\n",
    "\n",
    "        `h_t = relu( fc(h_t_prev) + fc(g_t) )`\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    - input_size: input size of the rnn.\n",
    "    - hidden_size: hidden size of the rnn.\n",
    "    - g_t: a 2D tensor of shape (B, hidden_size). The glimpse\n",
    "      representation returned by the glimpse network for the\n",
    "      current timestep `t`.\n",
    "    - h_t_prev: a 2D tensor of shape (B, hidden_size). The\n",
    "      hidden state vector for the previous timestep `t-1`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - h_t: a 2D tensor of shape (B, hidden_size). The hidden\n",
    "      state vector for the current timestep `t`.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(core_network, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, g_t, h_t_prev):\n",
    "        h1 = self.i2h(g_t)\n",
    "        h2 = self.h2h(h_t_prev)\n",
    "        h_t = F.relu(h1 + h2)\n",
    "        return h_t\n",
    "\n",
    "\n",
    "class action_network(nn.Module):\n",
    "    \"\"\"\n",
    "    Uses the internal state `h_t` of the core network to\n",
    "    produce the final output classification.\n",
    "\n",
    "    Concretely, feeds the hidden state `h_t` through a fc\n",
    "    layer followed by a softmax to create a vector of\n",
    "    output probabilities over the possible classes.\n",
    "\n",
    "    Hence, the environment action `a_t` is drawn from a\n",
    "    distribution conditioned on an affine transformation\n",
    "    of the hidden state vector `h_t`, or in other words,\n",
    "    the action network is simply a linear softmax classifier.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    - input_size: input size of the fc layer.\n",
    "    - output_size: output size of the fc layer.\n",
    "    - h_t: the hidden state vector of the core network for\n",
    "      the current time step `t`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - a_t: output probability vector over the classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(action_network, self).__init__()\n",
    "        print (input_size)\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Linear(input_size, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(input_size, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 29))\n",
    "    def forward(self, h_t):\n",
    "        #a_t = F.log_softmax(self.fc(h_t), dim=1)\n",
    "        a_t = self.model.forward(h_t)\n",
    "        #print (a_t.shape)\n",
    "        return a_t\n",
    "\n",
    "\n",
    "class location_network(nn.Module):\n",
    "    \"\"\"\n",
    "    Uses the internal state `h_t` of the core network to\n",
    "    produce the location coordinates `l_t` for the next\n",
    "    time step.\n",
    "\n",
    "    Concretely, feeds the hidden state `h_t` through a fc\n",
    "    layer followed by a tanh to clamp the output beween\n",
    "    [-1, 1]. This produces a 2D vector of means used to\n",
    "    parametrize a two-component Gaussian with a fixed\n",
    "    variance from which the location coordinates `l_t`\n",
    "    for the next time step are sampled.\n",
    "\n",
    "    Hence, the location `l_t` is chosen stochastically\n",
    "    from a distribution conditioned on an affine\n",
    "    transformation of the hidden state vector `h_t`.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    - input_size: input size of the fc layer.\n",
    "    - output_size: output size of the fc layer.\n",
    "    - std: standard deviation of the normal distribution.\n",
    "    - h_t: the hidden state vector of the core network for\n",
    "      the current time step `t`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - mu: a 2D vector of shape (B, 2).\n",
    "    - l_t: a 2D vector of shape (B, 2).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, std):\n",
    "        super(location_network, self).__init__()\n",
    "        self.std = std\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, h_t):\n",
    "        # compute mean\n",
    "        mu = F.tanh(self.fc(h_t.detach()))\n",
    "\n",
    "        # reparametrization trick\n",
    "        noise = torch.zeros_like(mu)\n",
    "        noise.data.normal_(std=self.std)\n",
    "        l_t = mu + noise\n",
    "\n",
    "        # bound between [-1, 1]\n",
    "        l_t = F.tanh(l_t)\n",
    "\n",
    "        return mu, l_t\n",
    "\n",
    "\n",
    "class baseline_network(nn.Module):\n",
    "    \"\"\"\n",
    "    Regresses the baseline in the reward function\n",
    "    to reduce the variance of the gradient update.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    - input_size: input size of the fc layer.\n",
    "    - output_size: output size of the fc layer.\n",
    "    - h_t: the hidden state vector of the core network\n",
    "      for the current time step `t`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    - b_t: a 2D vector of shape (B, 1). The baseline\n",
    "      for the current time step `t`.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(baseline_network, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 29)\n",
    "        #self.fc2 = nn.Linear(1000,1)\n",
    "\n",
    "    def forward(self, h_t):\n",
    "        #b_t = self.fc2(F.relu(self.fc1(h_t.detach())))\n",
    "        b_t = self.fc1(h_t.detach())\n",
    "        return b_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8saGg9FpNzu"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.distributions import Normal\n",
    "\n",
    "\n",
    "class RecurrentAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A Recurrent Model of Visual Attention (RAM) [1].\n",
    "\n",
    "    RAM is a recurrent neural network that processes\n",
    "    inputs sequentially, attending to different locations\n",
    "    within the image one at a time, and incrementally\n",
    "    combining information from these fixations to build\n",
    "    up a dynamic internal representation of the image.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    - Minh et. al., https://arxiv.org/abs/1406.6247\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 k,\n",
    "                 s,\n",
    "                 c,\n",
    "                 h_g,\n",
    "                 h_l,\n",
    "                 std,\n",
    "                 hidden_size,\n",
    "                 num_classes):\n",
    "        \"\"\"\n",
    "        Initialize the recurrent attention model and its\n",
    "        different components.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        - g: size of the square patches in the glimpses extracted\n",
    "          by the retina.\n",
    "        - k: number of patches to extract per glimpse.\n",
    "        - s: scaling factor that controls the size of successive patches.\n",
    "        - c: number of channels in each image.\n",
    "        - h_g: hidden layer size of the fc layer for `phi`.\n",
    "        - h_l: hidden layer size of the fc layer for `l`.\n",
    "        - std: standard deviation of the Gaussian policy.\n",
    "        - hidden_size: hidden size of the rnn.\n",
    "        - num_classes: number of classes in the dataset.\n",
    "        - num_glimpses: number of glimpses to take per image,\n",
    "          i.e. number of BPTT steps.\n",
    "        \"\"\"\n",
    "        super(RecurrentAttention, self).__init__()\n",
    "        self.std = std\n",
    "\n",
    "        self.sensor = glimpse_network(h_g, h_l, g, k, s, c)\n",
    "        self.rnn = core_network(hidden_size, hidden_size)\n",
    "        self.locator = location_network(hidden_size, 2, std)\n",
    "        self.classifier = action_network(hidden_size, num_classes)\n",
    "        self.baseliner = baseline_network(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, l_t_prev, h_t_prev, last=False):\n",
    "        \"\"\"\n",
    "        Run the recurrent attention model for 1 timestep\n",
    "        on the minibatch of images `x`.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        - x: a 4D Tensor of shape (B, H, W, C). The minibatch\n",
    "          of images.\n",
    "        - l_t_prev: a 2D tensor of shape (B, 2). The location vector\n",
    "          containing the glimpse coordinates [x, y] for the previous\n",
    "          timestep `t-1`.\n",
    "        - h_t_prev: a 2D tensor of shape (B, hidden_size). The hidden\n",
    "          state vector for the previous timestep `t-1`.\n",
    "        - last: a bool indicating whether this is the last timestep.\n",
    "          If True, the action network returns an output probability\n",
    "          vector over the classes and the baseline `b_t` for the\n",
    "          current timestep `t`. Else, the core network returns the\n",
    "          hidden state vector for the next timestep `t+1` and the\n",
    "          location vector for the next timestep `t+1`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        - h_t: a 2D tensor of shape (B, hidden_size). The hidden\n",
    "          state vector for the current timestep `t`.\n",
    "        - mu: a 2D tensor of shape (B, 2). The mean that parametrizes\n",
    "          the Gaussian policy.\n",
    "        - l_t: a 2D tensor of shape (B, 2). The location vector\n",
    "          containing the glimpse coordinates [x, y] for the\n",
    "          current timestep `t`.\n",
    "        - b_t: a vector of length (B,). The baseline for the\n",
    "          current time step `t`.\n",
    "        - log_probas: a 2D tensor of shape (B, num_classes). The\n",
    "          output log probability vector over the classes.\n",
    "        - log_pi: a vector of length (B,).\n",
    "        \"\"\"\n",
    "        g_t = self.sensor(x, l_t_prev)\n",
    "        h_t = self.rnn(g_t, h_t_prev)\n",
    "        mu, l_t = self.locator(h_t)\n",
    "        b_t = self.baseliner(h_t).squeeze()\n",
    "\n",
    "        # we assume both dimensions are independent\n",
    "        # 1. pdf of the joint is the product of the pdfs\n",
    "        # 2. log of the product is the sum of the logs\n",
    "        log_pi = Normal(mu, self.std).log_prob(l_t)\n",
    "        log_pi = torch.sum(log_pi, dim=1)\n",
    "\n",
    "        if last:\n",
    "            log_probas = self.classifier(h_t)\n",
    "            #return h_t, l_t, log_probas, log_pi\n",
    "            return h_t, l_t, b_t, log_probas, log_pi\n",
    "\n",
    "        return h_t, l_t,b_t, log_pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5RwPV02pNzx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from utils import AverageMeter\n",
    "#from model import RecurrentAttention\n",
    "from tensorboard_logger import configure, log_value\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Trainer encapsulates all the logic necessary for\n",
    "    training the Recurrent Attention Model.\n",
    "\n",
    "    All hyperparameters are provided by the user in the\n",
    "    config file.\n",
    "    \"\"\"\n",
    "    def __init__(self, config, data_loader):\n",
    "        \"\"\"- h_t: a 2D tensor of shape (B, hidden_size). The hidden\n",
    "          state vector for the current timestep `t`.\n",
    "        - mu: a 2D tensor of shape (B, 2). The mean that parametrizes\n",
    "          the Gaussian policy.\n",
    "        - l_t: a 2D tensor of shape (B, 2). The location vector\n",
    "          containing the glimpse coordinates [x, y] for the\n",
    "          current timestep `t`.\n",
    "        - b_t: a vector of length (B,). The baseline for the\n",
    "          current time step `t`.\n",
    "        - log_probas: a 2D tensor of shape (B, num_classes). The\n",
    "          output log probability vector over the classes.\n",
    "        - log_pi: a vector of length (B,).\n",
    "        Construct a new Trainer instance.\n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        - config: object containing command line arguments.\n",
    "        - data_loader: data iterator\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "\n",
    "        # glimpse network params\n",
    "        self.patch_size = config.patch_size\n",
    "        self.glimpse_scale = config.glimpse_scale\n",
    "        self.num_patches = config.num_patches\n",
    "        self.loc_hidden = config.loc_hidden\n",
    "        self.glimpse_hidden = config.glimpse_hidden\n",
    "\n",
    "        # core network params\n",
    "        self.num_glimpses = config.num_glimpses\n",
    "        self.hidden_size = config.hidden_size\n",
    "\n",
    "        # reinforce params\n",
    "        self.std = config.std\n",
    "        self.M = config.M\n",
    "\n",
    "        # data params\n",
    "        if config.is_train:\n",
    "            self.train_loader = data_loader[0]\n",
    "            self.valid_loader = data_loader[1]\n",
    "            self.num_train = len(self.train_loader.sampler.indices)\n",
    "            self.num_valid = len(self.valid_loader.sampler.indices)\n",
    "        else:\n",
    "            self.test_loader = data_loader\n",
    "            self.num_test = len(self.test_loader.dataset)\n",
    "        self.num_classes = 29\n",
    "        self.num_channels = 1\n",
    "\n",
    "        # training params\n",
    "        self.epochs = config.epochs\n",
    "        self.start_epoch = 0\n",
    "        self.momentum = config.momentum\n",
    "        self.lr = config.init_lr\n",
    "\n",
    "        # misc params\n",
    "        self.use_gpu = config.use_gpu\n",
    "        self.best = config.best\n",
    "        self.ckpt_dir = config.ckpt_dir\n",
    "        self.logs_dir = config.logs_dir\n",
    "        self.best_valid_acc = 0.\n",
    "        self.counter = 0\n",
    "        self.lr_patience = config.lr_patience\n",
    "        self.train_patience = config.train_patience\n",
    "        self.use_tensorboard = config.use_tensorboard\n",
    "        self.resume = config.resume\n",
    "        self.print_freq = config.print_freq\n",
    "        self.plot_freq = config.plot_freq\n",
    "        self.model_name = 'ram_{}_{}x{}_{}'.format(\n",
    "            config.num_glimpses, config.patch_size,\n",
    "            config.patch_size, config.glimpse_scale\n",
    "        )\n",
    "\n",
    "        self.plot_dir = './plots/' + self.model_name + '/'\n",
    "        if not os.path.exists(self.plot_dir):\n",
    "            os.makedirs(self.plot_dir)\n",
    "\n",
    "        # configure tensorboard logging\n",
    "        if self.use_tensorboard:\n",
    "            tensorboard_dir = self.logs_dir + self.model_name\n",
    "            print('[*] Saving tensorboard logs to {}'.format(tensorboard_dir))\n",
    "            if not os.path.exists(tensorboard_dir):\n",
    "                os.makedirs(tensorboard_dir)\n",
    "            configure(tensorboard_dir)\n",
    "\n",
    "        # build RAM model\n",
    "        self.model = RecurrentAttention(\n",
    "            self.patch_size, self.num_patches, self.glimpse_scale,\n",
    "            self.num_channels, self.loc_hidden, self.glimpse_hidden,\n",
    "            self.std, self.hidden_size, self.num_classes,\n",
    "        )\n",
    "        if self.use_gpu:\n",
    "            self.model.cuda()\n",
    "\n",
    "        print('[*] Number of model parameters: {:,}'.format(\n",
    "            sum([p.data.nelement() for p in self.model.parameters()])))\n",
    "\n",
    "        # # initialize optimizer and scheduler\n",
    "        # self.optimizer = optim.SGD(\n",
    "        #     self.model.parameters(), lr=self.lr, momentum=self.momentum,\n",
    "        # )\n",
    "        # self.scheduler = ReduceLROnPlateau(\n",
    "        #     self.optimizer, 'min', patience=self.lr_patience\n",
    "        # )\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(), lr=3e-4,\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state of the core network\n",
    "        and the location vector.\n",
    "\n",
    "        This is called once every time a new minibatch\n",
    "        `x` is introduced.\n",
    "        \"\"\"\n",
    "        dtype = (\n",
    "            torch.cuda.FloatTensor if self.use_gpu else torch.FloatTensor\n",
    "        )\n",
    "\n",
    "        h_t = torch.zeros(self.batch_size, self.hidden_size)\n",
    "        h_t = Variable(h_t).type(dtype)\n",
    "\n",
    "        l_t = torch.Tensor(self.batch_size, 2).uniform_(-1, 1)\n",
    "        l_t = Variable(l_t).type(dtype)\n",
    "\n",
    "        return h_t, l_t\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model on the training set.\n",
    "\n",
    "        A checkpoint of the model is saved after each epoch\n",
    "        and if the validation accuracy is improved upon,\n",
    "        a separate ckpt is created for use on the test set.\n",
    "        \"\"\"\n",
    "        # load the most recent checkpoint\n",
    "        if self.resume:\n",
    "            self.load_checkpoint(self.best)\n",
    "            \n",
    "        if self.use_gpu:\n",
    "            self.model.cuda()\n",
    "            \n",
    "        print(\"\\n[*] Train on {} samples, validate on {} samples\".format(\n",
    "            self.num_train, self.num_valid)\n",
    "        )\n",
    "\n",
    "        for epoch in range(self.start_epoch, self.epochs):\n",
    "\n",
    "            print(\n",
    "                '\\nEpoch: {}/{} - LR: {:.6f}'.format(\n",
    "                    epoch+1, self.epochs, self.lr)\n",
    "            )\n",
    "\n",
    "            # train for 1 epoch\n",
    "            train_loss, train_acc = self.train_one_epoch(epoch)\n",
    "\n",
    "            # evaluate on validation set\n",
    "            valid_loss, valid_acc = self.validate(epoch)\n",
    "\n",
    "            # # reduce lr if validation loss plateaus\n",
    "            # self.scheduler.step(valid_loss)\n",
    "\n",
    "            is_best = valid_acc < self.best_valid_acc\n",
    "            msg1 = \"train loss: {:.3f} - train acc: {:.3f} \"\n",
    "            msg2 = \"- val loss: {:.3f} - val acc: {:.3f}\"\n",
    "            if is_best:\n",
    "                self.counter = 0\n",
    "                msg2 += \" [*]\"\n",
    "            msg = msg1 + msg2\n",
    "            log_file = open(str(self.num_patches)+\"_\"+str(self.num_glimpses)+\"_\"+str(self.glimpse_scale)+\".txt\", \"a+\")\n",
    "            log_file.write(msg.format(train_loss, train_acc, valid_loss, valid_acc))\n",
    "            log_file.write(\"\\n\")\n",
    "            log_file.close()\n",
    "            print(msg.format(train_loss, train_acc, valid_loss, valid_acc))\n",
    "\n",
    "            # check for improvement\n",
    "            if not is_best:\n",
    "                self.counter += 1\n",
    "            if self.counter > self.train_patience:\n",
    "                print(\"[!] No improvement in a while, stopping training.\")\n",
    "                return\n",
    "            self.best_valid_acc = min(valid_acc, self.best_valid_acc)\n",
    "            self.save_checkpoint(\n",
    "                {'epoch': epoch + 1,\n",
    "                 'model_state': self.model.state_dict(),\n",
    "                 'optim_state': self.optimizer.state_dict(),\n",
    "                 'best_valid_acc': self.best_valid_acc,\n",
    "                 }, is_best\n",
    "            )\n",
    "\n",
    "    def train_one_epoch(self, epoch):\n",
    "        \"\"\"\n",
    "        Train the model for 1 epoch of the training set.\n",
    "\n",
    "        An epoch corresponds to one full pass through the entire\n",
    "        training set in successive mini-batches.\n",
    "\n",
    "        This is used by train() and should not be called manually.\n",
    "        \"\"\"\n",
    "        batch_time = AverageMeter()\n",
    "        losses = AverageMeter()\n",
    "        accs = AverageMeter()\n",
    "\n",
    "        tic = time.time()\n",
    "        with tqdm(total=self.num_train) as pbar:\n",
    "            for i, (x, y) in enumerate(self.train_loader):\n",
    "                x = x.type(torch.FloatTensor)\n",
    "                if self.use_gpu:\n",
    "                    x, y = x.cuda(), y.cuda()\n",
    "\n",
    "                x, y = Variable(x), Variable(y)\n",
    "\n",
    "                plot = False\n",
    "                if (epoch % self.plot_freq == 0) and (i == 0):\n",
    "                    plot = True\n",
    "\n",
    "                # initialize location vector and hidden state\n",
    "                self.batch_size = x.shape[0]\n",
    "                h_t, l_t = self.reset()\n",
    "\n",
    "                # save images\n",
    "                imgs = []\n",
    "                imgs.append(x[0:9])\n",
    "\n",
    "                # extract the glimpses\n",
    "                locs = []\n",
    "                log_pi = []\n",
    "                baselines = []\n",
    "                for t in range(self.num_glimpses - 1):\n",
    "                    # forward pass through model\n",
    "                    h_t, l_t,b_t, p = self.model(x, l_t, h_t)\n",
    "\n",
    "                    # store\n",
    "                    locs.append(l_t[0:9])\n",
    "                    baselines.append(b_t)\n",
    "                    log_pi.append(p)\n",
    "\n",
    "                # last iteration\n",
    "                h_t, l_t,b_t, log_probas, p = self.model(\n",
    "                    x, l_t, h_t, last=True\n",
    "                )\n",
    "                \n",
    "                log_pi.append(p)\n",
    "                baselines.append(b_t)\n",
    "                locs.append(l_t[0:9])\n",
    "\n",
    "                # convert list to tensors and reshape\n",
    "                \n",
    "                \n",
    "                baselines = torch.stack(baselines).transpose(1, 0)\n",
    "                y = y.type(torch.FloatTensor)\n",
    "                if self.use_gpu:\n",
    "                    y =y.cuda()\n",
    "                log_pi = torch.stack(log_pi).transpose(1, 0)\n",
    "                y_copy = y.clone()\n",
    "                log_prob_det = log_probas.detach()\n",
    "                log_prob_det[y!=y]=0\n",
    "                y[y!=y]=0\n",
    "                \n",
    "                R = (log_prob_det.detach()-y).abs().float()\n",
    "                R = R.unsqueeze(1)\n",
    "                R = R.repeat(1, self.num_glimpses,1)\n",
    "            \n",
    "                \n",
    "                adjusted_reward = R - baselines.detach()#32*7*29\n",
    "                log_pi = log_pi.unsqueeze(2).repeat(1,1,29)#32*7*29\n",
    "                loss_reinforce = torch.sum(-log_pi * adjusted_reward, dim=[1,2])\n",
    "                loss_reinforce = torch.mean(loss_reinforce, dim=0)\n",
    "                loss_action = F.mse_loss(log_probas[~torch.isnan(y_copy)],y_copy[~torch.isnan(y_copy)])\n",
    "                loss_baseline = F.mse_loss(baselines, R)\n",
    "                \n",
    "                loss = loss_reinforce+loss_action+loss_baseline\n",
    "\n",
    "\n",
    "                acc = F.mse_loss(log_probas[~torch.isnan(y_copy)],y_copy[~torch.isnan(y_copy)])\n",
    "                \n",
    "                # store\n",
    "                losses.update(loss.item(), x.size()[0])\n",
    "                accs.update(acc.item(), x.size()[0])\n",
    "\n",
    "                # compute gradients and update SGD\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # measure elapsed time\n",
    "                toc = time.time()\n",
    "                batch_time.update(toc-tic)\n",
    "\n",
    "                pbar.set_description(\n",
    "                    (\n",
    "                        \"{:.1f}s - loss: {:.3f} - acc: {:.3f}\".format(\n",
    "                            (toc-tic), loss.item(), acc.item()\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                pbar.update(self.batch_size)\n",
    "\n",
    "                # dump the glimpses and locs\n",
    "                if plot:\n",
    "                    if self.use_gpu:\n",
    "                        imgs = [g.cpu().data.numpy().squeeze() for g in imgs]\n",
    "                        locs = [l.cpu().data.numpy() for l in locs]\n",
    "                    else:\n",
    "                        imgs = [g.data.numpy().squeeze() for g in imgs]\n",
    "                        locs = [l.data.numpy() for l in locs]\n",
    "                    pickle.dump(\n",
    "                        imgs, open(\n",
    "                            self.plot_dir + \"g_{}.p\".format(epoch+1),\n",
    "                            \"wb\"\n",
    "                        )\n",
    "                    )\n",
    "                    pickle.dump(\n",
    "                        locs, open(\n",
    "                            self.plot_dir + \"l_{}.p\".format(epoch+1),\n",
    "                            \"wb\"\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                # log to tensorboard\n",
    "                if self.use_tensorboard:\n",
    "                    iteration = epoch*len(self.train_loader) + i\n",
    "                    log_value('train_loss', losses.avg, iteration)\n",
    "                    log_value('train_acc', accs.avg, iteration)\n",
    "\n",
    "            return losses.avg, accs.avg\n",
    "\n",
    "    def validate(self, epoch):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the validation set.\n",
    "        \"\"\"\n",
    "        losses = AverageMeter()\n",
    "        accs = AverageMeter()\n",
    "\n",
    "        for i, (x, y) in enumerate(self.valid_loader):\n",
    "            x = x.type(torch.FloatTensor)\n",
    "            y = y.type(torch.FloatTensor)\n",
    "            if self.use_gpu:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            x, y = Variable(x), Variable(y)\n",
    "\n",
    "            # duplicate 10 times\n",
    "            x = x.repeat(self.M, 1, 1, 1)\n",
    "\n",
    "            # initialize location vector and hidden state\n",
    "            self.batch_size = x.shape[0]\n",
    "            h_t, l_t = self.reset()\n",
    "\n",
    "            # extract the glimpses\n",
    "            log_pi = []\n",
    "            baselines = []\n",
    "            for t in range(self.num_glimpses - 1):\n",
    "                # forward pass through model\n",
    "                h_t, l_t,b_t, p = self.model(x, l_t, h_t)\n",
    "\n",
    "                # store\n",
    "                baselines.append(b_t)\n",
    "                log_pi.append(p)\n",
    "\n",
    "            # last iteration\n",
    "            h_t, l_t,b_t, log_probas, p = self.model(\n",
    "                x, l_t, h_t, last=True\n",
    "            )\n",
    "            log_pi.append(p)\n",
    "            baselines.append(b_t)\n",
    "            \n",
    "            # convert list to tensors and reshape\n",
    "            baselines = torch.stack(baselines).transpose(1, 0)\n",
    "            log_pi = torch.stack(log_pi).transpose(1, 0)\n",
    "            log_probas = log_probas.view(\n",
    "                self.M, -1, log_probas.shape[-1]\n",
    "            )\n",
    "            #print(log_probas.shape)\n",
    "            \n",
    "            log_probas = torch.mean(log_probas, dim=0)\n",
    "            #print(baselines.shape)\n",
    "            baselines = baselines.contiguous().view(\n",
    "                self.M, -1, baselines.shape[-2], baselines.shape[-1]\n",
    "            )\n",
    "            #print(baselines.shape)\n",
    "            baselines = torch.mean(baselines, dim=0)\n",
    "            #print(baselines.shape)\n",
    "            \n",
    "            log_pi = log_pi.contiguous().view(\n",
    "                self.M, -1, log_pi.shape[-1]\n",
    "            )\n",
    "            log_pi = torch.mean(log_pi, dim=0)\n",
    "            \n",
    "            y = y.type(torch.FloatTensor)\n",
    "            if self.use_gpu:\n",
    "                y =y.cuda()\n",
    "            \n",
    "            y_copy = y.clone()\n",
    "            log_prob_det = log_probas.detach()\n",
    "            log_prob_det[y!=y]=0\n",
    "            y[y!=y]=0\n",
    "\n",
    "            R = (log_prob_det.detach()-y).abs().float()\n",
    "            R = R.unsqueeze(1)\n",
    "            R = R.repeat(1, self.num_glimpses,1)\n",
    "            \n",
    "            adjusted_reward = R - baselines.detach()#32*7*29\n",
    "            \n",
    "            log_pi = log_pi.unsqueeze(2).repeat(1,1,29)#32*7*29\n",
    "            loss_reinforce = torch.sum(-log_pi * adjusted_reward, dim=[1,2])#\n",
    "            \n",
    "            loss_reinforce = torch.mean(loss_reinforce, dim=0)\n",
    "            \n",
    "            loss_action = F.mse_loss(log_probas[~torch.isnan(y_copy)],y_copy[~torch.isnan(y_copy)])\n",
    "            \n",
    "            loss_baseline = F.mse_loss(baselines, R)\n",
    "            \n",
    "            loss = loss_reinforce+loss_action+loss_baseline\n",
    "            \n",
    "            \n",
    "            acc = F.mse_loss(log_probas[~torch.isnan(y_copy)],y_copy[~torch.isnan(y_copy)])\n",
    "\n",
    "            # store\n",
    "            losses.update(loss.item(), x.size()[0])\n",
    "            accs.update(acc.item(), x.size()[0])\n",
    "\n",
    "            # log to tensorboard\n",
    "            if self.use_tensorboard:\n",
    "                iteration = epoch*len(self.valid_loader) + i\n",
    "                log_value('valid_loss', losses.avg, iteration)\n",
    "                log_value('valid_acc', accs.avg, iteration)\n",
    "\n",
    "        return losses.avg, accs.avg\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        Test the model on the held-out test data.\n",
    "        This function should only be called at the very\n",
    "        end once the model has finished training.\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "\n",
    "        # load the best checkpoint\n",
    "        self.load_checkpoint(best=self.best)\n",
    "\n",
    "        for i, (x, y) in enumerate(self.test_loader):\n",
    "            if self.use_gpu:\n",
    "                x, y = x.cuda(), y.cuda()\n",
    "            x, y = Variable(x, volatile=True), Variable(y)\n",
    "\n",
    "            # duplicate 10 times\n",
    "            x = x.repeat(self.M, 1, 1, 1)\n",
    "\n",
    "            # initialize location vector and hidden state\n",
    "            self.batch_size = x.shape[0]\n",
    "            h_t, l_t = self.reset()\n",
    "\n",
    "            # extract the glimpses\n",
    "            for t in range(self.num_glimpses - 1):\n",
    "                # forward pass through model\n",
    "                h_t, l_t, b_t, p = self.model(x, l_t, h_t)\n",
    "\n",
    "            # last iteration\n",
    "            h_t, l_t, b_t, log_probas, p = self.model(\n",
    "                x, l_t, h_t, last=True\n",
    "            )\n",
    "\n",
    "            log_probas = log_probas.view(\n",
    "                self.M, -1, log_probas.shape[-1]\n",
    "            )\n",
    "            log_probas = torch.mean(log_probas, dim=0)\n",
    "\n",
    "            pred = log_probas.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        perc = (100. * correct) / (self.num_test)\n",
    "        error = 100 - perc\n",
    "        print(\n",
    "            '[*] Test Acc: {}/{} ({:.2f}% - {:.2f}%)'.format(\n",
    "                correct, self.num_test, perc, error)\n",
    "        )\n",
    "\n",
    "    def save_checkpoint(self, state, is_best):\n",
    "        \"\"\"\n",
    "        Save a copy of the model so that it can be loaded at a future\n",
    "        date. This function is used when the model is being evaluated\n",
    "        on the test data.\n",
    "\n",
    "        If this model has reached the best validation accuracy thus\n",
    "        far, a seperate file with the suffix `best` is created.\n",
    "        \"\"\"\n",
    "        # print(\"[*] Saving model to {}\".format(self.ckpt_dir))\n",
    "\n",
    "        filename = self.model_name + '_ckpt.pth.tar'\n",
    "        ckpt_path = os.path.join(self.ckpt_dir, filename)\n",
    "        torch.save(state, ckpt_path)\n",
    "\n",
    "        if is_best:\n",
    "            filename = self.model_name + '_model_best.pth.tar'\n",
    "            shutil.copyfile(\n",
    "                ckpt_path, os.path.join(self.ckpt_dir, filename)\n",
    "            )\n",
    "\n",
    "    def load_checkpoint(self, best=False):\n",
    "        \"\"\"\n",
    "        Load the best copy of a model. This is useful for 2 cases:\n",
    "\n",
    "        - Resuming training with the most recent model checkpoint.\n",
    "        - Loading the best validation model to evaluate on the test data.\n",
    "\n",
    "        Params\n",
    "        ------\n",
    "        - best: if set to True, loads the best model. Use this if you want\n",
    "          to evaluate your model on the test data. Else, set to False in\n",
    "          which case the most recent version of the checkpoint is used.\n",
    "        \"\"\"\n",
    "        print(\"[*] Loading model from {}\".format(self.ckpt_dir))\n",
    "\n",
    "        filename = self.model_name + '_ckpt.pth.tar'\n",
    "        if best:\n",
    "            filename = self.model_name + '_model_best.pth.tar'\n",
    "        ckpt_path = os.path.join(self.ckpt_dir, filename)\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "\n",
    "        # load variables from checkpoint\n",
    "        self.start_epoch = ckpt['epoch']\n",
    "        self.best_valid_acc = ckpt['best_valid_acc']\n",
    "        self.model.load_state_dict(ckpt['model_state'])\n",
    "        self.optimizer.load_state_dict(ckpt['optim_state'])\n",
    "\n",
    "        if best:\n",
    "            print(\n",
    "                \"[*] Loaded {} checkpoint @ epoch {} \"\n",
    "                \"with best valid acc of {:.3f}\".format(\n",
    "                    filename, ckpt['epoch'], ckpt['best_valid_acc'])\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"[*] Loaded {} checkpoint @ epoch {}\".format(\n",
    "                    filename, ckpt['epoch'])\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpK4_C4ppNza"
   },
   "outputs": [],
   "source": [
    "#Params of model\n",
    "class Config(object):\n",
    "      def __init__(self):\n",
    "        #size of extracted patch at highest res\n",
    "        self.patch_size =64\n",
    "\n",
    "        #Scale of successive patches\n",
    "        self.glimpse_scale = 2\n",
    "\n",
    "        # # of downscaled patches per glimpse\n",
    "        self.num_patches = 2\n",
    "\n",
    "        #hidden size of loc fc\n",
    "        self.loc_hidden = 256\n",
    "\n",
    "        #hidden size of glimpse fc\n",
    "        self.glimpse_hidden = 256\n",
    "\n",
    "        # core network params\n",
    "        ## of glimpses, i.e. BPTT iterations\n",
    "        self.num_glimpses = 7\n",
    "\n",
    "        #hidden size of rnn  \n",
    "        self.hidden_size = 512\n",
    "\n",
    "        # reinforce params\n",
    "\n",
    "        #gaussian policy standard deviation\n",
    "        self.std = 0.17 #0.17\n",
    "        #Monte Carlo sampling for valid and test sets\n",
    "        self.M = 10\n",
    "\n",
    "        # data params\n",
    "        #Proportion of training set used for validation\n",
    "        self.valid_size=0.1\n",
    "\n",
    "        ## of images in each batch of data\n",
    "        self.batch_size = 32\n",
    "\n",
    "        ## of subprocesses to use for data loading\n",
    "        self.num_workers = 4\n",
    "\n",
    "        #Whether to shuffle the train and valid indices\n",
    "        self.shuffle = True\n",
    "\n",
    "        #Whether to visualize a sample grid of the data\n",
    "        self.show_sample=False\n",
    "\n",
    "        # training params\n",
    "\n",
    "        #Whether to train or test the model\n",
    "        self.is_train = True\n",
    "\n",
    "        #Whether to train or test the model\n",
    "        self.momentum=0.5\n",
    "\n",
    "        ## of epochs to train for\n",
    "        self.epochs = 500\n",
    "\n",
    "        #Initial learning rate value\n",
    "        self.init_lr = 3e-4\n",
    "\n",
    "        #Number of epochs to wait before reducing lr\n",
    "        self.lr_patience = 100\n",
    "\n",
    "        #Number of epochs to wait before stopping train\n",
    "        self.train_patience = 100\n",
    "\n",
    "        # other params\n",
    "        #Whether to run on the GPU\n",
    "        self.use_gpu = True\n",
    "\n",
    "        #Load best model or most recent for testing\n",
    "        self.best = False\n",
    "        #Seed to ensure reproducibility\n",
    "        self.random_seed = 1\n",
    "\n",
    "        #Directory in which data is stored\n",
    "        self.data_dir = './data'\n",
    "\n",
    "        #Directory in which to save model checkpoints\n",
    "        self.ckpt_dir = './ckpt'\n",
    "        #Directory in which Tensorboard logs wil be stored\n",
    "        self.logs_dir='./logs/'\n",
    "        #Whether to use tensorboard for visualization\n",
    "        self.use_tensorboard= True\n",
    "        #Whether to resume training from checkpoint\n",
    "        self.resume = False\n",
    "\n",
    "        #How frequently to print training details\n",
    "        self.print_freq = 10\n",
    "        #How frequently to plot glimpses\n",
    "        self.plot_freq = 1\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "NBBlo8HLpNz1",
    "outputId": "86056d7e-e600-4a0b-a3f8-6ed83f0cb01b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workstation/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\r",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggregate_tox.csv\n",
      "Cuda testing\n",
      "Ura\n",
      "[*] Saving tensorboard logs to ./logs/ram_7_64x64_2\n",
      "512\n",
      "[*] Number of model parameters: 3,442,748\n",
      "[*] Model Checkpoint Dir: ./ckpt\n",
      "[*] Param Path: ./ckpt/ram_7_64x64_2_params.json\n",
      "\n",
      "[*] Train on 78357 samples, validate on 8706 samples\n",
      "\n",
      "Epoch: 1/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188.9s - loss: 27.471 - acc: 0.564: 100%|██████████| 78357/78357 [03:08<00:00, 477.40it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 7.574 - train acc: 1.123 - val loss: 37.973 - val acc: 0.659\n",
      "\n",
      "Epoch: 2/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187.9s - loss: 34.995 - acc: 0.597: 100%|██████████| 78357/78357 [03:07<00:00, 394.26it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.883 - train acc: 0.771 - val loss: 38.589 - val acc: 0.639\n",
      "\n",
      "Epoch: 3/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188.5s - loss: -5.247 - acc: 0.355: 100%|██████████| 78357/78357 [03:08<00:00, 475.06it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 1.011 - train acc: 0.735 - val loss: -5.886 - val acc: 0.617\n",
      "\n",
      "Epoch: 4/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183.7s - loss: -5.154 - acc: 0.611: 100%|██████████| 78357/78357 [03:03<00:00, 400.88it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.703 - train acc: 0.714 - val loss: -3.578 - val acc: 0.950\n",
      "\n",
      "Epoch: 5/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186.2s - loss: 0.388 - acc: 0.436: 100%|██████████| 78357/78357 [03:06<00:00, 509.51it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.708 - train acc: 0.693 - val loss: -0.108 - val acc: 0.614\n",
      "\n",
      "Epoch: 6/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176.7s - loss: 1.464 - acc: 0.439: 100%|██████████| 78357/78357 [02:56<00:00, 443.33it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.667 - train acc: 0.674 - val loss: 1.013 - val acc: 0.624\n",
      "\n",
      "Epoch: 7/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175.2s - loss: 1.712 - acc: 0.503: 100%|██████████| 78357/78357 [02:55<00:00, 447.00it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.363 - train acc: 0.650 - val loss: 0.253 - val acc: 0.618\n",
      "\n",
      "Epoch: 8/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166.9s - loss: 2.197 - acc: 0.670: 100%|██████████| 78357/78357 [02:46<00:00, 448.98it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.406 - train acc: 0.645 - val loss: 0.657 - val acc: 0.615\n",
      "\n",
      "Epoch: 9/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.2s - loss: -3.102 - acc: 0.828: 100%|██████████| 78357/78357 [02:49<00:00, 450.61it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.685 - train acc: 0.639 - val loss: 0.562 - val acc: 0.611\n",
      "\n",
      "Epoch: 10/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.0s - loss: 0.018 - acc: 1.184: 100%|██████████| 78357/78357 [02:48<00:00, 446.04it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.662 - train acc: 0.639 - val loss: 0.628 - val acc: 0.610\n",
      "\n",
      "Epoch: 11/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161.9s - loss: 2.121 - acc: 0.353: 100%|██████████| 78357/78357 [02:41<00:00, 483.93it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.672 - train acc: 0.637 - val loss: 0.532 - val acc: 0.615\n",
      "\n",
      "Epoch: 12/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.0s - loss: 1.680 - acc: 0.635: 100%|██████████| 78357/78357 [02:50<00:00, 448.12it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.649 - train acc: 0.638 - val loss: 0.797 - val acc: 0.602\n",
      "\n",
      "Epoch: 13/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.0s - loss: 1.135 - acc: 0.313: 100%|██████████| 78357/78357 [02:51<00:00, 427.21it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.701 - train acc: 0.638 - val loss: 0.667 - val acc: 0.612\n",
      "\n",
      "Epoch: 14/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.9s - loss: 1.598 - acc: 0.595: 100%|██████████| 78357/78357 [02:47<00:00, 466.46it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.659 - train acc: 0.635 - val loss: 0.781 - val acc: 0.610\n",
      "\n",
      "Epoch: 15/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.0s - loss: 1.610 - acc: 0.648: 100%|██████████| 78357/78357 [02:38<00:00, 450.81it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.699 - train acc: 0.635 - val loss: 0.432 - val acc: 0.611\n",
      "\n",
      "Epoch: 16/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.0s - loss: 2.002 - acc: 0.442: 100%|██████████| 78357/78357 [02:48<00:00, 472.93it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.658 - train acc: 0.637 - val loss: 0.706 - val acc: 0.604\n",
      "\n",
      "Epoch: 17/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.4s - loss: 1.869 - acc: 0.431: 100%|██████████| 78357/78357 [02:48<00:00, 417.73it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.674 - train acc: 0.633 - val loss: 0.717 - val acc: 0.600\n",
      "\n",
      "Epoch: 18/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173.0s - loss: 1.580 - acc: 0.736: 100%|██████████| 78357/78357 [02:53<00:00, 447.66it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.678 - train acc: 0.634 - val loss: 0.567 - val acc: 0.604\n",
      "\n",
      "Epoch: 19/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166.0s - loss: 1.595 - acc: 0.613: 100%|██████████| 78357/78357 [02:45<00:00, 441.74it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.637 - train acc: 0.632 - val loss: 0.787 - val acc: 0.609\n",
      "\n",
      "Epoch: 20/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.7s - loss: -1.795 - acc: 0.422: 100%|██████████| 78357/78357 [02:47<00:00, 442.38it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.686 - train acc: 0.634 - val loss: 0.561 - val acc: 0.605\n",
      "\n",
      "Epoch: 21/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.2s - loss: 0.643 - acc: 0.577: 100%|██████████| 78357/78357 [02:48<00:00, 451.82it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.667 - train acc: 0.633 - val loss: 0.552 - val acc: 0.610\n",
      "\n",
      "Epoch: 22/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162.7s - loss: 0.049 - acc: 0.503: 100%|██████████| 78357/78357 [02:42<00:00, 481.42it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.622 - train acc: 0.631 - val loss: 0.743 - val acc: 0.609\n",
      "\n",
      "Epoch: 23/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.9s - loss: -0.584 - acc: 0.914: 100%|██████████| 78357/78357 [02:49<00:00, 461.11it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.646 - train acc: 0.634 - val loss: 0.751 - val acc: 0.611\n",
      "\n",
      "Epoch: 24/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165.1s - loss: 0.467 - acc: 0.645: 100%|██████████| 78357/78357 [02:45<00:00, 474.35it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.683 - train acc: 0.631 - val loss: 0.619 - val acc: 0.608\n",
      "\n",
      "Epoch: 25/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166.5s - loss: 1.026 - acc: 0.437: 100%|██████████| 78357/78357 [02:46<00:00, 450.64it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.673 - train acc: 0.633 - val loss: 0.618 - val acc: 0.614\n",
      "\n",
      "Epoch: 26/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166.2s - loss: 2.742 - acc: 0.226: 100%|██████████| 78357/78357 [02:46<00:00, 443.09it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.652 - train acc: 0.633 - val loss: 0.618 - val acc: 0.611\n",
      "\n",
      "Epoch: 27/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.0s - loss: 2.421 - acc: 0.401: 100%|██████████| 78357/78357 [02:49<00:00, 452.02it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.640 - train acc: 0.632 - val loss: 0.718 - val acc: 0.606\n",
      "\n",
      "Epoch: 28/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.9s - loss: 2.164 - acc: 0.304: 100%|██████████| 78357/78357 [02:49<00:00, 461.01it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.653 - train acc: 0.631 - val loss: 0.620 - val acc: 0.607\n",
      "\n",
      "Epoch: 29/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.4s - loss: 0.951 - acc: 0.524: 100%|██████████| 78357/78357 [02:50<00:00, 448.18it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.659 - train acc: 0.630 - val loss: 0.570 - val acc: 0.606\n",
      "\n",
      "Epoch: 30/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162.5s - loss: 2.298 - acc: 0.327: 100%|██████████| 78357/78357 [02:42<00:00, 448.37it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.668 - train acc: 0.632 - val loss: 0.514 - val acc: 0.613\n",
      "\n",
      "Epoch: 31/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.5s - loss: -3.465 - acc: 1.238: 100%|██████████| 78357/78357 [02:49<00:00, 441.44it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.648 - train acc: 0.633 - val loss: 0.693 - val acc: 0.607\n",
      "\n",
      "Epoch: 32/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.9s - loss: 1.698 - acc: 0.463: 100%|██████████| 78357/78357 [02:47<00:00, 466.46it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.656 - train acc: 0.632 - val loss: 0.737 - val acc: 0.604\n",
      "\n",
      "Epoch: 33/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.4s - loss: 0.980 - acc: 0.486: 100%|██████████| 78357/78357 [02:52<00:00, 461.74it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.670 - train acc: 0.630 - val loss: 0.588 - val acc: 0.607\n",
      "\n",
      "Epoch: 34/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.5s - loss: 1.962 - acc: 0.761: 100%|██████████| 78357/78357 [02:50<00:00, 450.11it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.663 - train acc: 0.632 - val loss: 0.606 - val acc: 0.613\n",
      "\n",
      "Epoch: 35/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171.4s - loss: 0.379 - acc: 0.483: 100%|██████████| 78357/78357 [02:51<00:00, 447.37it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.653 - train acc: 0.631 - val loss: 0.691 - val acc: 0.608\n",
      "\n",
      "Epoch: 36/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.7s - loss: -0.779 - acc: 0.486: 100%|██████████| 78357/78357 [02:49<00:00, 461.68it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.676 - train acc: 0.632 - val loss: 0.569 - val acc: 0.608\n",
      "\n",
      "Epoch: 37/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.7s - loss: 0.558 - acc: 0.418: 100%|██████████| 78357/78357 [02:50<00:00, 434.76it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.657 - train acc: 0.633 - val loss: 0.696 - val acc: 0.607\n",
      "\n",
      "Epoch: 38/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171.0s - loss: 0.952 - acc: 0.565: 100%|██████████| 78357/78357 [02:51<00:00, 443.25it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.687 - train acc: 0.633 - val loss: 0.705 - val acc: 0.600\n",
      "\n",
      "Epoch: 39/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.0s - loss: 0.965 - acc: 0.305: 100%|██████████| 78357/78357 [02:49<00:00, 450.59it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.645 - train acc: 0.632 - val loss: 0.506 - val acc: 0.602\n",
      "\n",
      "Epoch: 40/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165.5s - loss: 1.401 - acc: 0.338: 100%|██████████| 78357/78357 [02:45<00:00, 447.10it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.663 - train acc: 0.630 - val loss: 0.730 - val acc: 0.611\n",
      "\n",
      "Epoch: 41/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.7s - loss: 2.368 - acc: 0.379: 100%|██████████| 78357/78357 [02:47<00:00, 439.99it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.668 - train acc: 0.633 - val loss: 0.759 - val acc: 0.613\n",
      "\n",
      "Epoch: 42/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.1s - loss: 2.148 - acc: 0.316: 100%|██████████| 78357/78357 [02:48<00:00, 446.11it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.677 - train acc: 0.632 - val loss: 0.456 - val acc: 0.605\n",
      "\n",
      "Epoch: 43/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165.2s - loss: 1.565 - acc: 0.357: 100%|██████████| 78357/78357 [02:45<00:00, 436.95it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.659 - train acc: 0.629 - val loss: 0.585 - val acc: 0.610\n",
      "\n",
      "Epoch: 44/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173.6s - loss: 1.513 - acc: 0.337: 100%|██████████| 78357/78357 [02:53<00:00, 450.25it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.660 - train acc: 0.633 - val loss: 0.683 - val acc: 0.607\n",
      "\n",
      "Epoch: 45/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.5s - loss: 1.177 - acc: 0.821: 100%|██████████| 78357/78357 [02:49<00:00, 431.30it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.652 - train acc: 0.629 - val loss: 0.566 - val acc: 0.609\n",
      "\n",
      "Epoch: 46/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.5s - loss: 0.524 - acc: 0.905: 100%|██████████| 78357/78357 [02:49<00:00, 445.78it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.666 - train acc: 0.630 - val loss: 0.783 - val acc: 0.615\n",
      "\n",
      "Epoch: 47/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.6s - loss: 1.177 - acc: 0.225: 100%|██████████| 78357/78357 [02:50<00:00, 460.75it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.673 - train acc: 0.631 - val loss: 0.565 - val acc: 0.606\n",
      "\n",
      "Epoch: 48/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.5s - loss: 0.446 - acc: 0.434: 100%|██████████| 78357/78357 [02:48<00:00, 448.40it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.662 - train acc: 0.630 - val loss: 0.660 - val acc: 0.608\n",
      "\n",
      "Epoch: 49/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.3s - loss: 0.965 - acc: 0.332: 100%|██████████| 78357/78357 [02:47<00:00, 449.31it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.668 - train acc: 0.633 - val loss: 0.733 - val acc: 0.609\n",
      "\n",
      "Epoch: 50/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.3s - loss: 1.532 - acc: 0.803: 100%|██████████| 78357/78357 [02:48<00:00, 437.91it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.654 - train acc: 0.628 - val loss: 0.577 - val acc: 0.611\n",
      "\n",
      "Epoch: 51/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.4s - loss: 2.147 - acc: 0.343: 100%|██████████| 78357/78357 [02:48<00:00, 465.21it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.661 - train acc: 0.630 - val loss: 0.619 - val acc: 0.606\n",
      "\n",
      "Epoch: 52/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166.0s - loss: 2.266 - acc: 0.343: 100%|██████████| 78357/78357 [02:46<00:00, 448.78it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.648 - train acc: 0.628 - val loss: 0.792 - val acc: 0.604\n",
      "\n",
      "Epoch: 53/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "163.9s - loss: 2.110 - acc: 0.375: 100%|██████████| 78357/78357 [02:43<00:00, 449.91it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.657 - train acc: 0.630 - val loss: 0.627 - val acc: 0.610\n",
      "\n",
      "Epoch: 54/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.9s - loss: 2.397 - acc: 0.316: 100%|██████████| 78357/78357 [02:48<00:00, 446.25it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.638 - train acc: 0.632 - val loss: 0.764 - val acc: 0.603\n",
      "\n",
      "Epoch: 55/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.4s - loss: 1.572 - acc: 0.328: 100%|██████████| 78357/78357 [02:49<00:00, 440.94it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.687 - train acc: 0.630 - val loss: 0.553 - val acc: 0.609\n",
      "\n",
      "Epoch: 56/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.3s - loss: 1.214 - acc: 0.313: 100%|██████████| 78357/78357 [02:48<00:00, 449.67it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.651 - train acc: 0.630 - val loss: 0.609 - val acc: 0.609\n",
      "\n",
      "Epoch: 57/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.4s - loss: 0.737 - acc: 0.618: 100%|██████████| 78357/78357 [02:47<00:00, 468.07it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.665 - train acc: 0.631 - val loss: 0.690 - val acc: 0.617\n",
      "\n",
      "Epoch: 58/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.1s - loss: 2.473 - acc: 0.284: 100%|██████████| 78357/78357 [02:48<00:00, 445.93it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.659 - train acc: 0.629 - val loss: 0.605 - val acc: 0.606\n",
      "\n",
      "Epoch: 59/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.4s - loss: -0.539 - acc: 0.549: 100%|██████████| 78357/78357 [02:50<00:00, 451.94it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.656 - train acc: 0.630 - val loss: 0.594 - val acc: 0.602\n",
      "\n",
      "Epoch: 60/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.6s - loss: 1.724 - acc: 0.588: 100%|██████████| 78357/78357 [02:49<00:00, 461.75it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.672 - train acc: 0.632 - val loss: 0.626 - val acc: 0.609\n",
      "\n",
      "Epoch: 61/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166.6s - loss: -5.460 - acc: 1.738: 100%|██████████| 78357/78357 [02:46<00:00, 447.52it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.660 - train acc: 0.629 - val loss: 0.661 - val acc: 0.610\n",
      "\n",
      "Epoch: 62/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.4s - loss: -0.696 - acc: 0.534: 100%|██████████| 78357/78357 [02:50<00:00, 442.07it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.665 - train acc: 0.631 - val loss: 0.521 - val acc: 0.606\n",
      "\n",
      "Epoch: 63/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166.3s - loss: 2.836 - acc: 0.846: 100%|██████████| 78357/78357 [02:46<00:00, 446.40it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.641 - train acc: 0.629 - val loss: 0.906 - val acc: 0.609\n",
      "\n",
      "Epoch: 64/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166.4s - loss: -1.128 - acc: 0.291: 100%|██████████| 78357/78357 [02:46<00:00, 422.71it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.674 - train acc: 0.629 - val loss: 0.406 - val acc: 0.606\n",
      "\n",
      "Epoch: 65/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165.6s - loss: -0.834 - acc: 0.682: 100%|██████████| 78357/78357 [02:45<00:00, 446.82it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.655 - train acc: 0.630 - val loss: 0.706 - val acc: 0.605\n",
      "\n",
      "Epoch: 66/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.0s - loss: 1.502 - acc: 0.287: 100%|██████████| 78357/78357 [02:48<00:00, 424.55it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.660 - train acc: 0.630 - val loss: 0.642 - val acc: 0.607\n",
      "\n",
      "Epoch: 67/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "162.8s - loss: 0.741 - acc: 0.561: 100%|██████████| 78357/78357 [02:42<00:00, 481.19it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.635 - train acc: 0.632 - val loss: 0.718 - val acc: 0.605\n",
      "\n",
      "Epoch: 68/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.3s - loss: -0.102 - acc: 1.085: 100%|██████████| 78357/78357 [02:50<00:00, 450.79it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.650 - train acc: 0.630 - val loss: 0.699 - val acc: 0.605\n",
      "\n",
      "Epoch: 69/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.1s - loss: 1.590 - acc: 0.275: 100%|██████████| 78357/78357 [02:48<00:00, 447.01it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.670 - train acc: 0.631 - val loss: 0.576 - val acc: 0.602\n",
      "\n",
      "Epoch: 70/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171.1s - loss: 1.733 - acc: 0.245: 100%|██████████| 78357/78357 [02:51<00:00, 424.69it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.659 - train acc: 0.630 - val loss: 0.726 - val acc: 0.612\n",
      "\n",
      "Epoch: 71/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.8s - loss: -1.576 - acc: 1.365: 100%|██████████| 78357/78357 [02:49<00:00, 453.99it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.653 - train acc: 0.629 - val loss: 0.682 - val acc: 0.612\n",
      "\n",
      "Epoch: 72/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.9s - loss: 0.889 - acc: 0.544: 100%|██████████| 78357/78357 [02:50<00:00, 398.36it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.669 - train acc: 0.628 - val loss: 0.630 - val acc: 0.606\n",
      "\n",
      "Epoch: 73/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161.4s - loss: 1.043 - acc: 0.588: 100%|██████████| 78357/78357 [02:41<00:00, 485.40it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.685 - train acc: 0.631 - val loss: 0.706 - val acc: 0.611\n",
      "\n",
      "Epoch: 74/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.1s - loss: 0.823 - acc: 0.921: 100%|██████████| 78357/78357 [02:49<00:00, 463.11it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.678 - train acc: 0.630 - val loss: 0.685 - val acc: 0.603\n",
      "\n",
      "Epoch: 75/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.5s - loss: -0.211 - acc: 0.909: 100%|██████████| 78357/78357 [02:49<00:00, 456.93it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.653 - train acc: 0.629 - val loss: 0.617 - val acc: 0.598\n",
      "\n",
      "Epoch: 76/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.1s - loss: 0.885 - acc: 0.414: 100%|██████████| 78357/78357 [02:49<00:00, 449.87it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.649 - train acc: 0.629 - val loss: 0.780 - val acc: 0.609\n",
      "\n",
      "Epoch: 77/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.3s - loss: 0.948 - acc: 0.675: 100%|██████████| 78357/78357 [02:50<00:00, 463.32it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.658 - train acc: 0.629 - val loss: 0.571 - val acc: 0.606\n",
      "\n",
      "Epoch: 78/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.4s - loss: 0.797 - acc: 0.507: 100%|██████████| 78357/78357 [02:49<00:00, 446.18it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.643 - train acc: 0.628 - val loss: 0.653 - val acc: 0.605\n",
      "\n",
      "Epoch: 79/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.5s - loss: -1.411 - acc: 0.651: 100%|██████████| 78357/78357 [02:52<00:00, 446.75it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.660 - train acc: 0.628 - val loss: 0.575 - val acc: 0.603\n",
      "\n",
      "Epoch: 80/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.3s - loss: -0.058 - acc: 0.384: 100%|██████████| 78357/78357 [02:50<00:00, 435.34it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.665 - train acc: 0.630 - val loss: 0.577 - val acc: 0.605\n",
      "\n",
      "Epoch: 81/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.6s - loss: 1.839 - acc: 0.240: 100%|██████████| 78357/78357 [02:47<00:00, 454.53it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.639 - train acc: 0.629 - val loss: 0.877 - val acc: 0.606\n",
      "\n",
      "Epoch: 82/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.7s - loss: 1.084 - acc: 0.426: 100%|██████████| 78357/78357 [02:47<00:00, 467.19it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.683 - train acc: 0.631 - val loss: 0.740 - val acc: 0.603\n",
      "\n",
      "Epoch: 83/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165.0s - loss: 2.823 - acc: 0.470: 100%|██████████| 78357/78357 [02:44<00:00, 437.07it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.634 - train acc: 0.628 - val loss: 0.712 - val acc: 0.607\n",
      "\n",
      "Epoch: 84/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165.3s - loss: 1.638 - acc: 0.347: 100%|██████████| 78357/78357 [02:45<00:00, 446.22it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.647 - train acc: 0.629 - val loss: 0.526 - val acc: 0.603\n",
      "\n",
      "Epoch: 85/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.9s - loss: 1.815 - acc: 0.503: 100%|██████████| 78357/78357 [02:49<00:00, 461.62it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.632 - train acc: 0.626 - val loss: 0.634 - val acc: 0.606\n",
      "\n",
      "Epoch: 86/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164.4s - loss: -7.107 - acc: 2.015: 100%|██████████| 78357/78357 [02:44<00:00, 448.78it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.658 - train acc: 0.626 - val loss: 0.623 - val acc: 0.607\n",
      "\n",
      "Epoch: 87/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164.9s - loss: 0.655 - acc: 0.368: 100%|██████████| 78357/78357 [02:44<00:00, 448.36it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.673 - train acc: 0.627 - val loss: 0.612 - val acc: 0.611\n",
      "\n",
      "Epoch: 88/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159.8s - loss: 1.286 - acc: 0.244: 100%|██████████| 78357/78357 [02:39<00:00, 490.24it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.659 - train acc: 0.628 - val loss: 0.643 - val acc: 0.608\n",
      "\n",
      "Epoch: 89/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.7s - loss: 1.290 - acc: 1.686: 100%|██████████| 78357/78357 [02:50<00:00, 448.61it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.652 - train acc: 0.628 - val loss: 0.689 - val acc: 0.616\n",
      "\n",
      "Epoch: 90/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171.1s - loss: 0.513 - acc: 0.513: 100%|██████████| 78357/78357 [02:51<00:00, 447.53it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.666 - train acc: 0.629 - val loss: 0.622 - val acc: 0.607\n",
      "\n",
      "Epoch: 91/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167.8s - loss: -0.429 - acc: 0.770: 100%|██████████| 78357/78357 [02:47<00:00, 437.70it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.661 - train acc: 0.627 - val loss: 0.569 - val acc: 0.607\n",
      "\n",
      "Epoch: 92/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.2s - loss: 1.814 - acc: 0.742: 100%|██████████| 78357/78357 [02:48<00:00, 434.24it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.653 - train acc: 0.628 - val loss: 0.685 - val acc: 0.610\n",
      "\n",
      "Epoch: 93/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170.8s - loss: 1.654 - acc: 0.206: 100%|██████████| 78357/78357 [02:50<00:00, 446.03it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.655 - train acc: 0.631 - val loss: 0.794 - val acc: 0.606\n",
      "\n",
      "Epoch: 94/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.9s - loss: 1.779 - acc: 0.578: 100%|██████████| 78357/78357 [02:49<00:00, 445.11it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.676 - train acc: 0.629 - val loss: 0.641 - val acc: 0.603\n",
      "\n",
      "Epoch: 95/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171.4s - loss: -0.642 - acc: 0.530: 100%|██████████| 78357/78357 [02:51<00:00, 447.94it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.635 - train acc: 0.629 - val loss: 0.842 - val acc: 0.612\n",
      "\n",
      "Epoch: 96/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169.3s - loss: 0.687 - acc: 0.265: 100%|██████████| 78357/78357 [02:49<00:00, 447.47it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.657 - train acc: 0.629 - val loss: 0.634 - val acc: 0.603\n",
      "\n",
      "Epoch: 97/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173.2s - loss: 0.268 - acc: 0.465: 100%|██████████| 78357/78357 [02:53<00:00, 440.47it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.633 - train acc: 0.629 - val loss: 0.870 - val acc: 0.610\n",
      "\n",
      "Epoch: 98/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164.0s - loss: -1.432 - acc: 0.755: 100%|██████████| 78357/78357 [02:44<00:00, 447.14it/s] \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.669 - train acc: 0.627 - val loss: 0.729 - val acc: 0.614\n",
      "\n",
      "Epoch: 99/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171.3s - loss: -0.423 - acc: 0.504: 100%|██████████| 78357/78357 [02:51<00:00, 457.35it/s]\n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.646 - train acc: 0.630 - val loss: 0.651 - val acc: 0.614\n",
      "\n",
      "Epoch: 100/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.4s - loss: 1.264 - acc: 0.587: 100%|██████████| 78357/78357 [02:48<00:00, 465.02it/s]  \n",
      "  0%|          | 0/78357 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.690 - train acc: 0.627 - val loss: 0.628 - val acc: 0.604\n",
      "\n",
      "Epoch: 101/500 - LR: 0.000300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168.8s - loss: 2.077 - acc: 0.327: 100%|██████████| 78357/78357 [02:48<00:00, 447.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.678 - train acc: 0.626 - val loss: 0.570 - val acc: 0.604\n",
      "[!] No improvement in a while, stopping training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"if __name__ == '__main__':\\n    config, unparsed = get_config()\\n    main(config)\""
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Main cell\n",
    "import torch\n",
    "\n",
    "#from trainer import Trainer\n",
    "#from config import get_config\n",
    "#from utils import prepare_dirs, save_config\n",
    "#from my_data_loader import get_test_loader, get_train_valid_loader\n",
    "\n",
    "\n",
    "# ensure directories are setup\n",
    "prepare_dirs(config)\n",
    "\n",
    "# ensure reproducibility\n",
    "torch.manual_seed(config.random_seed)\n",
    "kwargs = {}\n",
    "if config.use_gpu:\n",
    "    torch.cuda.manual_seed(config.random_seed)\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "# instantiate data loaders\n",
    "if config.is_train:\n",
    "    data_loader = get_train_valid_loader(\n",
    "        config.data_dir, config.batch_size,\n",
    "        config.random_seed, config.valid_size,\n",
    "        config.shuffle, config.show_sample, **kwargs\n",
    "    )\n",
    "else:\n",
    "    data_loader = get_test_loader(\n",
    "        config.data_dir, config.batch_size, **kwargs\n",
    "    )\n",
    "\n",
    "# instantiate trainer\n",
    "print (\"Cuda testing\")\n",
    "if (torch.cuda.is_available()):\n",
    "    print(\"Ura\")\n",
    "trainer = Trainer(config, data_loader)\n",
    "\n",
    "# either train\n",
    "if config.is_train:\n",
    "    save_config(config)\n",
    "    trainer.train()\n",
    "\n",
    "# or load a pretrained model and test\n",
    "else:\n",
    "    trainer.test()\n",
    "\n",
    "\n",
    "'''if __name__ == '__main__':\n",
    "    config, unparsed = get_config()\n",
    "    main(config)'''\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MainToxicity.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
